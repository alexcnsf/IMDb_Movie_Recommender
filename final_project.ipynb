{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre_Action, Adventure' 'Genre_Action, Adventure, Biography'\n",
      " 'Genre_Action, Adventure, Comedy' 'Genre_Action, Adventure, Crime'\n",
      " 'Genre_Action, Adventure, Drama' 'Genre_Action, Adventure, Family'\n",
      " 'Genre_Action, Adventure, Fantasy' 'Genre_Action, Adventure, History'\n",
      " 'Genre_Action, Adventure, Horror' 'Genre_Action, Adventure, Mystery'\n",
      " 'Genre_Action, Adventure, Romance' 'Genre_Action, Adventure, Sci-Fi'\n",
      " 'Genre_Action, Adventure, Thriller' 'Genre_Action, Adventure, War'\n",
      " 'Genre_Action, Adventure, Western' 'Genre_Action, Biography, Crime'\n",
      " 'Genre_Action, Biography, Drama' 'Genre_Action, Comedy, Crime'\n",
      " 'Genre_Action, Comedy, Fantasy' 'Genre_Action, Comedy, Mystery'\n",
      " 'Genre_Action, Comedy, Romance' 'Genre_Action, Crime, Comedy'\n",
      " 'Genre_Action, Crime, Drama' 'Genre_Action, Crime, Mystery'\n",
      " 'Genre_Action, Crime, Thriller' 'Genre_Action, Drama'\n",
      " 'Genre_Action, Drama, History' 'Genre_Action, Drama, Mystery'\n",
      " 'Genre_Action, Drama, Sci-Fi' 'Genre_Action, Drama, Sport'\n",
      " 'Genre_Action, Drama, Thriller' 'Genre_Action, Drama, War'\n",
      " 'Genre_Action, Drama, Western' 'Genre_Action, Mystery, Thriller'\n",
      " 'Genre_Action, Sci-Fi' 'Genre_Action, Sci-Fi, Thriller'\n",
      " 'Genre_Action, Thriller' 'Genre_Adventure, Biography, Crime'\n",
      " 'Genre_Adventure, Biography, Drama' 'Genre_Adventure, Comedy, Crime'\n",
      " 'Genre_Adventure, Comedy, Drama' 'Genre_Adventure, Comedy, Family'\n",
      " 'Genre_Adventure, Comedy, Fantasy' 'Genre_Adventure, Comedy, Film-Noir'\n",
      " 'Genre_Adventure, Comedy, Sci-Fi' 'Genre_Adventure, Comedy, War'\n",
      " 'Genre_Adventure, Drama' 'Genre_Adventure, Drama, Fantasy'\n",
      " 'Genre_Adventure, Drama, History' 'Genre_Adventure, Drama, Musical'\n",
      " 'Genre_Adventure, Drama, Romance' 'Genre_Adventure, Drama, Sci-Fi'\n",
      " 'Genre_Adventure, Drama, Thriller' 'Genre_Adventure, Drama, War'\n",
      " 'Genre_Adventure, Drama, Western' 'Genre_Adventure, Family, Fantasy'\n",
      " 'Genre_Adventure, Fantasy' 'Genre_Adventure, History, War'\n",
      " 'Genre_Adventure, Horror, Sci-Fi' 'Genre_Adventure, Mystery, Thriller'\n",
      " 'Genre_Adventure, Sci-Fi' 'Genre_Adventure, Thriller'\n",
      " 'Genre_Animation, Action, Adventure' 'Genre_Animation, Action, Crime'\n",
      " 'Genre_Animation, Action, Drama' 'Genre_Animation, Action, Fantasy'\n",
      " 'Genre_Animation, Action, Sci-Fi' 'Genre_Animation, Adventure, Comedy'\n",
      " 'Genre_Animation, Adventure, Drama' 'Genre_Animation, Adventure, Family'\n",
      " 'Genre_Animation, Adventure, Fantasy' 'Genre_Animation, Biography, Crime'\n",
      " 'Genre_Animation, Biography, Drama' 'Genre_Animation, Comedy, Crime'\n",
      " 'Genre_Animation, Comedy, Drama' 'Genre_Animation, Comedy, Fantasy'\n",
      " 'Genre_Animation, Crime, Mystery' 'Genre_Animation, Drama, Family'\n",
      " 'Genre_Animation, Drama, Fantasy' 'Genre_Animation, Drama, Romance'\n",
      " 'Genre_Animation, Drama, War' 'Genre_Animation, Family, Fantasy'\n",
      " 'Genre_Animation, Sci-Fi' 'Genre_Biography, Comedy, Drama'\n",
      " 'Genre_Biography, Crime, Drama' 'Genre_Biography, Drama'\n",
      " 'Genre_Biography, Drama, Family' 'Genre_Biography, Drama, History'\n",
      " 'Genre_Biography, Drama, Music' 'Genre_Biography, Drama, Romance'\n",
      " 'Genre_Biography, Drama, Sport' 'Genre_Biography, Drama, Thriller'\n",
      " 'Genre_Biography, Drama, War' 'Genre_Comedy' 'Genre_Comedy, Crime'\n",
      " 'Genre_Comedy, Crime, Drama' 'Genre_Comedy, Crime, Mystery'\n",
      " 'Genre_Comedy, Crime, Romance' 'Genre_Comedy, Crime, Sport'\n",
      " 'Genre_Comedy, Crime, Thriller' 'Genre_Comedy, Drama'\n",
      " 'Genre_Comedy, Drama, Family' 'Genre_Comedy, Drama, Fantasy'\n",
      " 'Genre_Comedy, Drama, Music' 'Genre_Comedy, Drama, Musical'\n",
      " 'Genre_Comedy, Drama, Romance' 'Genre_Comedy, Drama, Thriller'\n",
      " 'Genre_Comedy, Drama, War' 'Genre_Comedy, Family'\n",
      " 'Genre_Comedy, Family, Fantasy' 'Genre_Comedy, Family, Romance'\n",
      " 'Genre_Comedy, Fantasy, Romance' 'Genre_Comedy, Horror'\n",
      " 'Genre_Comedy, Music' 'Genre_Comedy, Music, Musical'\n",
      " 'Genre_Comedy, Music, Romance' 'Genre_Comedy, Musical, Romance'\n",
      " 'Genre_Comedy, Musical, War' 'Genre_Comedy, Mystery, Romance'\n",
      " 'Genre_Comedy, Romance' 'Genre_Comedy, War' 'Genre_Comedy, Western'\n",
      " 'Genre_Crime, Drama' 'Genre_Crime, Drama, Fantasy'\n",
      " 'Genre_Crime, Drama, Film-Noir' 'Genre_Crime, Drama, History'\n",
      " 'Genre_Crime, Drama, Horror' 'Genre_Crime, Drama, Music'\n",
      " 'Genre_Crime, Drama, Musical' 'Genre_Crime, Drama, Mystery'\n",
      " 'Genre_Crime, Drama, Romance' 'Genre_Crime, Drama, Sci-Fi'\n",
      " 'Genre_Crime, Drama, Thriller' 'Genre_Crime, Film-Noir, Mystery'\n",
      " 'Genre_Crime, Film-Noir, Thriller' 'Genre_Crime, Mystery, Thriller'\n",
      " 'Genre_Crime, Thriller' 'Genre_Drama' 'Genre_Drama, Family'\n",
      " 'Genre_Drama, Family, Fantasy' 'Genre_Drama, Family, Musical'\n",
      " 'Genre_Drama, Family, Sport' 'Genre_Drama, Fantasy'\n",
      " 'Genre_Drama, Fantasy, History' 'Genre_Drama, Fantasy, Horror'\n",
      " 'Genre_Drama, Fantasy, Music' 'Genre_Drama, Fantasy, Mystery'\n",
      " 'Genre_Drama, Fantasy, Romance' 'Genre_Drama, Fantasy, War'\n",
      " 'Genre_Drama, Film-Noir' 'Genre_Drama, Film-Noir, Mystery'\n",
      " 'Genre_Drama, Film-Noir, Romance' 'Genre_Drama, History'\n",
      " 'Genre_Drama, History, Music' 'Genre_Drama, History, Mystery'\n",
      " 'Genre_Drama, History, Romance' 'Genre_Drama, History, Thriller'\n",
      " 'Genre_Drama, History, War' 'Genre_Drama, Horror'\n",
      " 'Genre_Drama, Horror, Mystery' 'Genre_Drama, Horror, Sci-Fi'\n",
      " 'Genre_Drama, Horror, Thriller' 'Genre_Drama, Music'\n",
      " 'Genre_Drama, Music, Musical' 'Genre_Drama, Music, Mystery'\n",
      " 'Genre_Drama, Music, Romance' 'Genre_Drama, Musical'\n",
      " 'Genre_Drama, Mystery' 'Genre_Drama, Mystery, Romance'\n",
      " 'Genre_Drama, Mystery, Sci-Fi' 'Genre_Drama, Mystery, Thriller'\n",
      " 'Genre_Drama, Mystery, War' 'Genre_Drama, Romance'\n",
      " 'Genre_Drama, Romance, Sci-Fi' 'Genre_Drama, Romance, Thriller'\n",
      " 'Genre_Drama, Romance, War' 'Genre_Drama, Sci-Fi'\n",
      " 'Genre_Drama, Sci-Fi, Thriller' 'Genre_Drama, Sport'\n",
      " 'Genre_Drama, Thriller' 'Genre_Drama, Thriller, War'\n",
      " 'Genre_Drama, Thriller, Western' 'Genre_Drama, War'\n",
      " 'Genre_Drama, War, Western' 'Genre_Drama, Western'\n",
      " 'Genre_Family, Fantasy, Musical' 'Genre_Family, Sci-Fi'\n",
      " 'Genre_Fantasy, Horror' 'Genre_Fantasy, Horror, Mystery'\n",
      " 'Genre_Film-Noir, Mystery' 'Genre_Film-Noir, Mystery, Thriller'\n",
      " 'Genre_Film-Noir, Thriller' 'Genre_Horror'\n",
      " 'Genre_Horror, Mystery, Sci-Fi' 'Genre_Horror, Mystery, Thriller'\n",
      " 'Genre_Horror, Sci-Fi' 'Genre_Horror, Thriller'\n",
      " 'Genre_Mystery, Romance, Thriller' 'Genre_Mystery, Sci-Fi, Thriller'\n",
      " 'Genre_Mystery, Thriller' 'Genre_Thriller' 'Genre_Western']\n",
      "[0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#file_path = '/Users/anasoni/Downloads/Big_Data_DIS/Final_project/imdb_top_1000.csv'\n",
    "file_path = 'data/imdb_top_1000.csv'\n",
    "\n",
    "df_raw = pd.read_csv(file_path)\n",
    "\n",
    "#print(df_raw['Certificate'].unique())\n",
    "\n",
    "rating_age_map = {\n",
    "    'A': 18, 'U': 0, 'UA': 7, 'U/A': 7, 'PG': 8, 'PG-13': 13, 'R': 17, 'G': 0, 'Passed': 0, 'Approved': 0, \n",
    "    'GP': 10, 'TV-14': 14, 'TV-MA': 17, 'TV-PG': 10, '16': 16, 'Unrated': None, 'NaN': None       \n",
    "}\n",
    "\n",
    "df_raw['Certificate'] = df_raw['Certificate'].map(rating_age_map)\n",
    "\n",
    "#df_raw['Runtime'] = df_raw['Runtime'].str.extract('(\\d+)').astype(int)\n",
    "df_raw['Genre'] = df_raw['Genre'].str.split(', ')\n",
    "\n",
    "df_raw['Gross'] = df_raw['Gross'].str.replace(\",\", \"\").astype(float)\n",
    "#df_raw['Released_Year'] = df_raw['Released_Year'].astype(float) # theres one pg so hard to compare here lol will look at this later\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "df_raw['overview_tfidf'] = list(tfidf.fit_transform(df_raw['Overview']).toarray())\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "directors_encoded = encoder.fit_transform(df_raw[['Director']])\n",
    "\n",
    "# df_raw\n",
    "# Transforming genre lists into a format suitable for OneHotEncoder\n",
    "\n",
    "# df_raw['Genre'] = df_raw['Genre'].apply(lambda x: ', '.join(x))\n",
    "# genres_encoded = encoder.fit_transform(df_raw[['Genre']])\n",
    "# genre_names = encoder.get_feature_names_out(['Genre'])\n",
    "# print(genre_names)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "#df_raw['Genre'] = df_raw['Genre'].apply(lambda x: x if isinstance(x, list) else (x.split(', ') if isinstance(x, str) else []))\n",
    "df_raw['Genre'] = df_raw['Genre'].apply(lambda x: ', '.join(x))\n",
    "genre_encoded = encoder.fit_transform(df_raw[['Genre']])\n",
    "genre_encoded = genre_encoded.toarray()\n",
    "genre_labels = encoder.get_feature_names_out() \n",
    "print(genre_labels)\n",
    "\n",
    "\n",
    "df_raw\n",
    "# Assuming encoder and genre_encoded are already created as shown previously\n",
    "# genre_labels = encoder.get_feature_names_out()  # This gets the genre labels used during encoding\n",
    "\n",
    "# genre_labels\n",
    "# # Convert genre_encoded array into a DataFrame\n",
    "# genre_df = pd.DataFrame(genre_encoded, columns=genre_labels)\n",
    "# # genre_encoded = encoder.fit_transform(df_raw['Genre'])\n",
    "# # genre_encoded = genre_encoded.toarray() \n",
    "# genre_df\n",
    "\n",
    "# def find_similar_movies(title, df, encoder):\n",
    "#     # Get the index of the movie\n",
    "#     idx = df[df['Title'] == title].index[0]\n",
    "    \n",
    "#     # Get the genre vector for the selected movie\n",
    "#     movie_vector = genre_encoded[idx]\n",
    "    \n",
    "#     # Compute dot products\n",
    "#     similarity = np.dot(genre_encoded, movie_vector)\n",
    "    \n",
    "#     # Get indices of movies with at least one genre in common\n",
    "#     similar_indices = np.where(similarity > 0)[0]\n",
    "    \n",
    "#     # Return titles of similar movies\n",
    "#     return df.iloc[similar_indices]['Title'].tolist()\n",
    "\n",
    "df_raw\n",
    "def find_similar_movies(title, df, encoder):\n",
    "    # Get the index of the movie\n",
    "    idx = df[df['Series_Title'] == title].index[0]\n",
    "    \n",
    "    movie_vector = genre_encoded[idx]\n",
    "    \n",
    "    # Compute dot products\n",
    "    similarity = np.dot(genre_encoded, movie_vector)\n",
    "    vect = []\n",
    "    for i in range(len(similarity)):\n",
    "        vect.append(similarity[i])\n",
    "\n",
    "    print(vect)\n",
    "        #     vect.append(similar_movies[i])\n",
    "\n",
    "    # print(vect) \n",
    "    # vect = s for  in similarity if similarity[]\n",
    "    # print(s if similarity[0] == 1)\n",
    "    \n",
    "    # # Get indices of movies with at least one genre in common\n",
    "    # similar_indices = np.where(similarity > 0.5)[0]\n",
    "\n",
    "    \n",
    "    # # Return titles of similar movies\n",
    "    # return df.iloc[similar_indices]['Series_Title'].tolist()\n",
    "\n",
    "#Example usage\n",
    "similar_movies = find_similar_movies(\"The Godfather\", df_raw, encoder)\n",
    "similar_movies\n",
    "# # Example usage\n",
    "# similar_movies = find_similar_movies('Your Movie Title', df_raw, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Poster_Link  \\\n",
      "18   https://m.media-amazon.com/images/M/MV5BNjViNW...   \n",
      "20   https://m.media-amazon.com/images/M/MV5BOTc2ZT...   \n",
      "30   https://m.media-amazon.com/images/M/MV5BYjBmYT...   \n",
      "32   https://m.media-amazon.com/images/M/MV5BZjc4ND...   \n",
      "46   https://m.media-amazon.com/images/M/MV5BZmY2Nj...   \n",
      "..                                                 ...   \n",
      "993  https://m.media-amazon.com/images/M/MV5BYTE4YW...   \n",
      "995  https://m.media-amazon.com/images/M/MV5BNGEwMT...   \n",
      "996  https://m.media-amazon.com/images/M/MV5BODk3Yj...   \n",
      "998  https://m.media-amazon.com/images/M/MV5BZTBmMj...   \n",
      "999  https://m.media-amazon.com/images/M/MV5BMTY5OD...   \n",
      "\n",
      "               Series_Title Released_Year  Certificate  Runtime  \\\n",
      "18                 Hamilton          2020         13.0      160   \n",
      "20          Soorarai Pottru          2020          0.0      153   \n",
      "30                  Seppuku          1962          NaN      133   \n",
      "32    It's a Wonderful Life          1946          8.0      130   \n",
      "46           Hotaru no haka          1988          0.0       89   \n",
      "..                      ...           ...          ...      ...   \n",
      "993                  Blowup          1966         18.0      111   \n",
      "995  Breakfast at Tiffany's          1961         18.0      115   \n",
      "996                   Giant          1956          0.0      201   \n",
      "998                Lifeboat          1944          NaN       97   \n",
      "999            The 39 Steps          1935          NaN       86   \n",
      "\n",
      "                           Genre  IMDB_Rating  \\\n",
      "18   [Biography, Drama, History]          8.6   \n",
      "20                       [Drama]          8.6   \n",
      "30      [Action, Drama, Mystery]          8.6   \n",
      "32      [Drama, Family, Fantasy]          8.6   \n",
      "46       [Animation, Drama, War]          8.5   \n",
      "..                           ...          ...   \n",
      "993   [Drama, Mystery, Thriller]          7.6   \n",
      "995     [Comedy, Drama, Romance]          7.6   \n",
      "996             [Drama, Western]          7.6   \n",
      "998                 [Drama, War]          7.6   \n",
      "999   [Crime, Mystery, Thriller]          7.6   \n",
      "\n",
      "                                              Overview  Meta_score  \\\n",
      "18   The real life of one of America's foremost fou...        90.0   \n",
      "20   Nedumaaran Rajangam \"Maara\" sets out to make t...         NaN   \n",
      "30   When a ronin requesting seppuku at a feudal lo...        85.0   \n",
      "32   An angel is sent from Heaven to help a despera...        89.0   \n",
      "46   A young boy and his little sister struggle to ...        94.0   \n",
      "..                                                 ...         ...   \n",
      "993  A fashion photographer unknowingly captures a ...        82.0   \n",
      "995  A young New York socialite becomes interested ...        76.0   \n",
      "996  Sprawling epic covering the life of a Texas ca...        84.0   \n",
      "998  Several survivors of a torpedoed merchant ship...        78.0   \n",
      "999  A man in London tries to help a counter-espion...        93.0   \n",
      "\n",
      "                   Director               Star1              Star2  \\\n",
      "18              Thomas Kail  Lin-Manuel Miranda       Phillipa Soo   \n",
      "20            Sudha Kongara              Suriya           Madhavan   \n",
      "30         Masaki Kobayashi     Tatsuya Nakadai     Akira Ishihama   \n",
      "32              Frank Capra       James Stewart         Donna Reed   \n",
      "46            Isao Takahata     Tsutomu Tatsumi    Ayano Shiraishi   \n",
      "..                      ...                 ...                ...   \n",
      "993  Michelangelo Antonioni      David Hemmings   Vanessa Redgrave   \n",
      "995           Blake Edwards      Audrey Hepburn     George Peppard   \n",
      "996          George Stevens    Elizabeth Taylor        Rock Hudson   \n",
      "998        Alfred Hitchcock   Tallulah Bankhead        John Hodiak   \n",
      "999        Alfred Hitchcock        Robert Donat  Madeleine Carroll   \n",
      "\n",
      "                Star3                   Star4  No_of_Votes  Gross  \\\n",
      "18    Leslie Odom Jr.  Renée Elise Goldsberry        55291    NaN   \n",
      "20       Paresh Rawal       Aparna Balamurali        54995    NaN   \n",
      "30     Shima Iwashita           Tetsurô Tanba        42004    NaN   \n",
      "32   Lionel Barrymore         Thomas Mitchell       405801    NaN   \n",
      "46    Akemi Yamaguchi       Yoshiko Shinohara       235231    NaN   \n",
      "..                ...                     ...          ...    ...   \n",
      "993       Sarah Miles             John Castle        56513    NaN   \n",
      "995     Patricia Neal             Buddy Ebsen       166544    NaN   \n",
      "996        James Dean           Carroll Baker        34075    NaN   \n",
      "998     Walter Slezak          William Bendix        26471    NaN   \n",
      "999    Lucie Mannheim          Godfrey Tearle        51853    NaN   \n",
      "\n",
      "                                        overview_tfidf  \n",
      "18   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "20   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "30   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "32   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "46   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "..                                                 ...  \n",
      "993  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "\n",
      "[286 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df_raw[df_raw.isna().any(axis=1)]\n",
    "print(nan_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Example function to calculate similarity\n",
    "def calculate_similarity(df, index):\n",
    "    similarities = {}\n",
    "    target = df.iloc[index]\n",
    "    for i, row in df.iterrows():\n",
    "        if i != index:\n",
    "            sim_score = 0\n",
    "            # Combine weighted scores from different features\n",
    "            sim_score += cosine_similarity([target['overview_tfidf']], [row['overview_tfidf']])[0][0]\n",
    "            # Add other similarities, weighted appropriately\n",
    "            similarities[row['Series_Title']] = sim_score\n",
    "    return sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def recommend_movies(title, top_n=10):\n",
    "    index = df_raw[df_raw['Series_Title'] == title].index[0]\n",
    "    recommendations = calculate_similarity(df_raw, index)\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Batman Begins', 0.20448886586574933),\n",
       " ('The Dark Knight Rises', 0.1776125825161448),\n",
       " ('Joker', 0.09853672377205022),\n",
       " ('Kill Bill: Vol. 1', 0.09273886468830328),\n",
       " ('La battaglia di Algeri', 0.08940649780155556),\n",
       " ('The Hurricane', 0.08039428178468236),\n",
       " ('Mulan', 0.07745579884006173),\n",
       " ('Wreck-It Ralph', 0.07729067757141045),\n",
       " ('Batman: Mask of the Phantasm', 0.07450408360309729),\n",
       " ('Jaws', 0.07192009751558806)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_movies('The Dark Knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m highest_gross \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df_raw\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 35\u001b[0m     lowest_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlowest_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReleased_Year\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     highest_year \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mmax\u001b[39m(highest_year, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReleased_Year\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     37\u001b[0m     lowest_runtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(lowest_runtime, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# def calculate_similarity(df, index):\n",
    "#     similarities = {}\n",
    "#     target = df.iloc[index]\n",
    "#     for i, row in df.iterrows():\n",
    "#         if i != index:\n",
    "#             sim_score = 0\n",
    "#             # Combine weighted scores from different features\n",
    "#             sim_score += cosine_similarity([target['overview_tfidf']], [row['overview_tfidf']])[0][0]\n",
    "#             # Add other similarities, weighted appropriately\n",
    "#             similarities[row['Series_Title']] = sim_score\n",
    "\n",
    "# description -  .35\n",
    "# genre - .2\n",
    "# the rating - .125\n",
    "# the critic score = .125\n",
    "# director = .1\n",
    "# release year = .05\n",
    "# GROSS = .05\n",
    "\n",
    "\n",
    "lowest_year = 1\n",
    "highest_year = -1 \n",
    "lowest_runtime = 1\n",
    "highest_runtime = -1 \n",
    "lowest_imdb = 1\n",
    "highest_imdb = -1 \n",
    "lowest_meta = 1\n",
    "highest_meta = -1 \n",
    "lowest_gross = 1\n",
    "highest_gross = -1 \n",
    "\n",
    "\n",
    "\n",
    "for i, row in df_raw.iterrows():\n",
    "    lowest_year = min(lowest_year, row[\"Released_Year\"])\n",
    "    highest_year =  max(highest_year, row[\"Released_Year\"])\n",
    "    lowest_runtime = min(lowest_runtime, row[\"Runtime\"])\n",
    "    highest_runtime = max(highest_runtime, row[\"Runtime\"]) \n",
    "    # lowest_imdb = 1\n",
    "    # highest_imdb = -1 \n",
    "    # lowest_meta = 1\n",
    "    # highest_meta = -1 \n",
    "    # lowest_gross = 1\n",
    "    # highest_gross = -1 \n",
    "    # # gross = row[\"Gross\"].replace(\",\", \"\")\n",
    "    # # New_Gross = int(gross)\n",
    "\n",
    "    # print(row[\"Gross\"])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17)\n",
      "(1000, 17)\n",
      "(1000, 17)\n",
      "(713, 17)\n"
     ]
    }
   ],
   "source": [
    "df = df_raw\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['Released_Year'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
    "print(df.shape)\n",
    "df['Runtime'] = pd.to_numeric(df['Runtime'], errors='coerce')\n",
    "df.shape\n",
    "df['IMDB_Rating'] = pd.to_numeric(df['IMDB_Rating'], errors='coerce')\n",
    "df.shape\n",
    "df['Meta_score'] = pd.to_numeric(df['Meta_score'], errors='coerce')\n",
    "print(df.shape)\n",
    "\n",
    "df.dropna(inplace=True)  # Remove rows with NaNs for simplicity\n",
    "print(df.shape)\n",
    "\n",
    "# The issue is dropping na gets rid of a lot of rows\n",
    "# We should first only drop rows missing data for features we will be using\n",
    "# And maybe instead of dropping row but assigning an average or predicting what it could be using the other rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Meta_Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/bigdata2024/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Meta_Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRuntime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRuntime\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMDB_Rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMDB_Rating\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeta_Score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMeta_Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Remove rows with NaNs for simplicity\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend_movies\u001b[39m(df, title):\n",
      "File \u001b[0;32m~/anaconda3/envs/bigdata2024/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/bigdata2024/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Meta_Score'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example data loading and preparation\n",
    "df = pd.read_csv('data/imdb_top_1000.csv')\n",
    "df['Released_Year'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
    "df['Runtime'] = pd.to_numeric(df['Runtime'], errors='coerce')\n",
    "df['IMDB_Rating'] = pd.to_numeric(df['IMDB_Rating'], errors='coerce')\n",
    "df['Meta_Score'] = pd.to_numeric(df['Meta_Score'], errors='coerce')\n",
    "df.dropna(inplace=True)  # Remove rows with NaNs for simplicity\n",
    "\n",
    "def recommend_movies(df, title):\n",
    "    target = df[df['Series_Title'] == title].iloc[0]\n",
    "    \n",
    "    # Create a DataFrame to store correlations for each movie\n",
    "    correlations = pd.DataFrame(df['Series_Title'], columns=['Series_Title'])\n",
    "    \n",
    "    # Calculate Pearson correlation for each feature\n",
    "    for feature in ['Released_Year', 'Runtime', 'IMDB_Rating', 'Meta_Score']:\n",
    "        correlations[feature] = df.apply(lambda row: np.corrcoef(df[feature], np.full(len(df), row[feature]))[0, 1], axis=1)\n",
    "    \n",
    "    # Calculate weighted similarity score\n",
    "    correlations['Similarity_Score'] = (\n",
    "        0.1 * correlations['Released_Year'] +\n",
    "        0.05 * correlations['Runtime'] +\n",
    "        0.15 * correlations['IMDB_Rating'] +\n",
    "        0.15 * correlations['Meta_Score']\n",
    "    )\n",
    "    \n",
    "    # Sort by similarity score in descending order and return the result\n",
    "    correlations.sort_values(by='Similarity_Score', ascending=False, inplace=True)\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "# Example usage\n",
    "title = 'The Dark Knight'\n",
    "similar_movies = recommend_movies(df, title)\n",
    "print(similar_movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept\n",
    "\n",
    "target = df[df['Series_Title'] == title].iloc[0]\n",
    "\n",
    "correlations = pd.DataFrame(df['Series_Title'], columns=['Series_Title'])\n",
    "\n",
    "# Using absolute differences instead of correlation for simplicity\n",
    "for feature in ['Released_Year', 'Runtime', 'IMDB_Rating', 'Meta_score']:\n",
    "    correlations[feature] = df[feature].apply(lambda x: abs(x - target[feature]))\n",
    "\n",
    "# Assuming normalization by the range might still be relevant\n",
    "correlations['Similarity_Score'] = (\n",
    "    correlations['Released_Year'] / (df['Released_Year'].max() - df['Released_Year'].min()) +\n",
    "    correlations['Runtime'] / (df['Runtime'].max() - df['Runtime'].min()) +\n",
    "    correlations['IMDB_Rating'] / (df['IMDB_Rating'].max() - df['IMDB_Rating'].min())\n",
    ")\n",
    "\n",
    "correlations.sort_values('Similarity_Score', inplace=True)\n",
    "\n",
    "print(correlations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decide how to deal with NaN rows\n",
    "2. Calculate similarity score for four numeric features (IMDB, Meta score, release year, runtime)\n",
    "3. Turn difference scores into 0 to 1 measurement (percent) to standardize it\n",
    "4. Apply wieghts\n",
    "5. Calculate best recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
